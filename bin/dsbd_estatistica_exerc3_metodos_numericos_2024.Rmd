---
title: "exerc3 - metodos numericos"
author: "Alceu Nascimento"
date: "2024-05-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(expm)
library(matlib)
library(Rlinsolve)
library(stats)
library(car)
library(pracma)

```

```{r formulas prof wagner, options}
# METODOS DE CONFINAMENTO

# BISSECAO
## algoritmo da bissecao
bissecao <- function(fx, a, b, tol = 1e-04, max_iter = 100) {
  fa <- fx(a); fb <- fx(b); if(fa*fb > 0) stop("Solução não está no intervalo")
  solucao <- c(); sol <- (a + b)/2; solucao[1] <- sol;
  limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for(i in 1:max_iter) {
    test <- fx(a)*fx(sol)
    if(test < 0) {
      solucao[i+1] <- (a + sol)/2
      b = sol }
    if(test > 0) {
      solucao[i+1] <- (b + sol)/2
      a = sol }
    if( abs( (b-a)/2) < tol) break
    sol = solucao[i+1]
    limites[i,] <- c(a,b) }
  out <- list("Tentativas" = solucao, "Limites" = limites, "Raiz" = solucao[i+1])
  return(out)
}

## implemento do argoritimo da bissecao
### funcao
ftheta <- function(theta){
  dd <- 2 * length(y) * (log(theta.hat/theta) + mean(y)*(theta - theta.hat) )
  return(dd - 3.84)
}

### Resolvendo numericamente
set.seed(123)
y <- rexp(20, rate = 1)
theta.hat <- 1/mean(y)
Ic_min <- bissecao(fx = ftheta, a = 0, b = theta.hat)
Ic_max <- bissecao(fx = ftheta, a = theta.hat, b = 3)
c(Ic_min$Raiz, Ic_max$Raiz) ## Solução aproximada


# REGULA FALSI
## algoritmo regula falsi
regula_falsi <- function(fx, a, b, tol = 1e-04, max_iter = 100) {
  fa <- fx(a); fb <- fx(b); if(fa*fb > 0) stop("Solução não está no intervalo")
  solucao <- c() ; sol <- (a*fx(b) - b*fx(a))/(fx(b) - fx(a))
  solucao[1] <- sol; limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for(i in 1:max_iter) {
    test <- fx(a)*fx(sol)
    if(test < 0) {
      b = sol
    solucao[i+1] <- (a*fx(b) - b*fx(a))/(fx(b) - fx(a)) }
    if(test > 0) {
      a = sol
      solucao[i+1] <- sol <- (a*fx(b) - b*fx(a))/(fx(b) - fx(a)) }
    if( abs(solucao[i+1] - solucao[i]) < tol) break
      sol = solucao[i+1]
      limites[i,] <- c(a,b) }
  out <- list("Tentativas" = solucao, "Limites" = limites, "Raiz" = sol)
  return(out)
}

## implemento do algorimto regula falsi
### Resolvendo numericamente
Ic_min <- regula_falsi(fx = ftheta, a = 0.1, b = theta.hat)
Ic_max <- regula_falsi(fx = ftheta, a = theta.hat, b = 3)
### Solução aproximada
c(Ic_min$Raiz, Ic_max$Raiz)


# METODOS ABERTOS

# NEWTON
## algoritmo de Newton
newton_ma <- function(fx, f_prime, x1, tol = 1e-04, max_iter = 10) {
  solucao <- c()
  solucao[1] <- x1
  for(i in 1:max_iter) {
    solucao[i+1] = solucao[i] - fx(solucao[i])/f_prime(solucao[i])
    if( abs(solucao[i+1] - solucao[i]) < tol) break
  }
  return(solucao)
}

## implemento do algoritmo de Newton
### Derivada da função a ser resolvida
fprime <- function(theta){2*length(y)*(mean(y) - 1/theta)}
### Solução numerica
Ic_min <- newton_ma(fx = ftheta, f_prime = fprime, x1 = 0.1)
Ic_max <- newton_ma(fx = ftheta, f_prime = fprime, x1 = 2)
c(Ic_min[length(Ic_min)], Ic_max[length(Ic_max)])



# GRADIENTE DESCENDENTE
## algoritmo de gradiente descendente
grad_des_ma <- function(fx, x1, alpha, max_iter = 100, tol = 1e-04) {
  sol <- c()
  sol[1] <- x1
  for(i in 1:max_iter) {
    sol[i+1] <- sol[i] - alpha*fx(sol[i])
    if(abs(fx(sol[i+1])) < tol) break
  }
return(sol)
}

## implemento do algotirmo de gradiente descendente
## Solução numerica
Ic_min <- grad_des_ma(fx = ftheta, alpha = -0.02, x1 = 0.1)
Ic_max <- grad_des_ma(fx = ftheta, alpha = 0.01, x1 = 4)
c(Ic_min[length(Ic_min)], Ic_max[length(Ic_max)])


```

```{r sistema de equacoes prof wagner, options}
# METODO DE NEWTON
## algoritmo de Newton
newton_sa <- function(fx, jacobian, x1, tol = 1e-04, max_iter = 10) {
  solucao <- matrix(NA, ncol = length(x1), nrow = max_iter)
  solucao[1,] <- x1
  for(i in 1:max_iter) {
    J <- jacobian(solucao[i,])
    grad <- fx(solucao[i,])
    solucao[i+1,] = solucao[i,] - solve(J, grad)
    if( sum(abs(solucao[i+1,] - solucao[i,])) < tol) break
  }
return(solucao)
}

## implemento do algoritimo de Newton

## Sistema a ser resolvido
fx <- function(x){
  c(x[2] - 0.5*(exp(x[1]/2) + exp(-x[1]/2)),9*x[1]^2 + 25*x[2]^2 - 225 )
}

## Jacobiano
Jacobian <- function(x) {
  jac <- matrix(NA,2,2)
  jac[1,1] <- -0.5*(exp(x[1]/2)/2 - exp(-x[1]/2)/2)
  jac[1,2] <- 1
  jac[2,1] <- 18*x[1]
  jac[2,2] <- 50*x[2]
return(jac)
}

## Resolvendo
sol <- newton_sa(fx = fx, jacobian = Jacobian, x1 = c(1,1))
### solucao
tail(sol,4)
## check if ok
fx(sol[8,])


# METODO GRADIENTE DESCENDENTE
## algoritmo de gradiente descentente
grad_des_sa <- function(fx, x1, alpha, max_iter = 100, tol = 1e-04) {
  solucao <- matrix(NA, ncol = length(x1), nrow = max_iter)
  solucao[1,] <- x1
  for(i in 1:c(max_iter-1)) {
    solucao[i+1,] <- solucao[i,] - alpha*fx(solucao[i,])
    #print(c(i, solucao[i+1,]))
    if( sum(abs(solucao[i+1,] - solucao[i,])) <= tol) break
  }
return(solucao)
}


## implemento do algoritmo de gradiente descendente
fx <- function(x) {
  y <- c(5.15, 6.40, 2.77, 5.72, 6.25, 3.45, 5.00, 6.86, 4.86, 3.72)
  z <- c(0.28, 0.78, 0.40, 0.88, 0.94, 0.04, 0.52, 0.89, 0.55, 0.45)
  term1 <- - 2*sum(y - x[1] - x[2]*z)
  term2 <- -2*sum( (y - x[1] - x[2]*z)*z)
  out <- c(term1, term2)
return(out)
}

sol_grad <- grad_des_sa(fx = fx, x1 = c(5, 0), alpha = 0.05, max_iter = 140)
fx(x = sol_grad[137,])


```

```{r diferenciacao numerica prof wagner, options}
# diferenca progressiva
dif_prog <- function(fx, x, h) {
  df <- (fx(x + h) - fx(x))/( (x + h) - x)
  return(df)
}

# diferenca regressiva
dif_reg <- function(fx, x, h) {
  df <- (fx(x) - fx(x - h))/( x - (x - h))
  return(df)
}

# diferenca central
dif_cen <- function(fx, x, h) {
df <- (fx(x + h) - fx(x - h))/( (x + h) - (x - h))
return(df)}

## implemento das diferencas
### aproximacao de derivadas por diferencas finitas
fx <- function(x) x^3
deriv_fx <- 3*2^2

dif_prog(fx, x = 2, h = 0.001) ## Diferença progressiva
dif_reg(fx, x = 2, h = 0.001) ## Diferença regressiva
dif_cen(fx, x = 2, h = 0.001) ## Diferença central
```

# 1 (parcialmente correta 0,333)

Encontre os valores de $β_0$ e $β_1$ que otimizam a seguinte função\
(descobrir se é um problema de maximização ou minimização é parte da questão).\
Utilize o método Gradiente Conjugado (CG) usando as opções `default` da função `optim()` em R.

$$
L = 
-\frac{1}{n} 
\sum^n_{i=1} 
(y_i \; \ln(μ_i) 
+ (1 − y_i) \; \ln(1 − μ_i) )
\text{,   onde } \; 
μ_i = 
\frac{\exp(β_0 + β_1 x_i)}{1 + exp(β_0 + β_1 x_i)}
$$

Como valores para $y_i$ e $x_i$ considere os seguintes valores.\
Na notação $n$ é o número de observações.\
Neste exercício $n=10$.\
Sua resposta são três valores: valor de $β_0$ , valor de $β_1$ e valor da função objetivo no ponto ótimo.\
Use três casas decimais.\
Use como valores iniciais $β0=0$ e $β1=0$.\
$x_i = 2, 1, 3, 0, 3, 3, 4, 2, 1, 1$\
$y_i = 1, 0, 0, 0, 1, 0, 1, 0, 0, 0$  

  
Resposta:   

A função $L$ é a log-verossimilhança negativa de um modelo de regressão logística, que deve ser minimizada para encontrar os melhores parâmetros $β_0$ e $β_1$.  


A função $L$ apresentada no exercício é a log-verossimilhança negativa de um modelo de regressão logística. A regressão logística é uma técnica estatística utilizada para modelar a probabilidade de um evento binário (com duas possíveis saídas) como uma função das variáveis independentes.  

Vamos detalhar a função LL:  

## Definição da Função LL  

A função LL é definida como:  
$$
L = -\frac{1}{n} \sum_{i=1}^n (y_i \ln(\mu_i) + (1 - y_i) \ln(1 - \mu_i))
$$

onde:  

- \( n \) é o número de observações.  
- \( y_i \) são as respostas observadas (variável dependente binária, com valores 0 ou 1).  
- \( \mu_i \) é a probabilidade estimada de que \( y_i \) seja 1, dada pelo modelo de regressão logística.  

A probabilidade \( \mu_i \) é modelada pela função logística:  
$$
\mu_i = \frac{\exp(\beta_0 + \beta_1 x_i)}{1 + \exp(\beta_0 + \beta_1 x_i)}
$$

onde:  

- \( x_i \) são os valores das variáveis independentes (preditores).  
- \( \beta_0 \) é o coeficiente de interceptação.  
- \( \beta_1 \) é o coeficiente da variável \( x_i \).  

## Interpretação da Função LL

A função LL é a log-verossimilhança negativa da função de verossimilhança do modelo de regressão logística. A função de verossimilhança mede o quão bem os parâmetros \( \beta_0 \) e \( \beta_1 \) ajustam o modelo aos dados observados. A verossimilhança \( LL \) é maximizada quando os parâmetros proporcionam a melhor concordância entre as probabilidades preditas \( \mu_i \) e as observações \( y_i \).  

No entanto, ao trabalhar com log-verossimilhança negativa, em vez de maximizar a verossimilhança, minimizamos a log-verossimilhança negativa para encontrar os melhores parâmetros \( \beta_0 \) e \( \beta_1 \).  

## Derivação da Função LL

Para cada observação \( i \), a contribuição para a log-verossimilhança é:  

- Se \( y_i = 1 \): \( \ln(\mu_i) \)
- Se \( y_i = 0 \): \( \ln(1 - \mu_i) \)

Assim, a log-verossimilhança para todas as observações é:  
$$
\sum_{i=1}^n (y_i \ln(\mu_i) + (1 - y_i) \ln(1 - \mu_i))
$$

Dividimos por \( -n \) para obter a log-verossimilhança negativa média:  
$$
L = -\frac{1}{n} \sum_{i=1}^n (y_i \ln(\mu_i) + (1 - y_i) \ln(1 - \mu_i))
$$

## Otimização

Para encontrar os valores de \( \beta_0 \) e \( \beta_1 \) que minimizam \( LL \), utilizamos o método do Gradiente Conjugado (CG). Esse método é adequado para minimizar funções não lineares e é implementado na função `optim()` do R.  


```{r 1}
# Dados fornecidos
xi <- c(2, 1, 3, 0, 3, 3, 4, 2, 1, 1)
yi <- c(1, 0, 0, 0, 1, 0, 1, 0, 0, 0)
n <- length(xi)

# Função objetivo corrigida
objective_function <- function(beta) {
  beta0 <- beta[1]
  beta1 <- beta[2]
  mu <- exp(beta0 + beta1 * xi) / (1 + exp(beta0 + beta1 * xi))
  L <- -sum(yi * log(mu) + (1 - yi) * log(1 - mu)) / n
  return(L)
}


# Valores iniciais
initial_values <- c(0, 0)

# Otimização utilizando o método Gradiente Conjugado (CG)
result <- optim(par = initial_values, fn = objective_function)
result

# Extraindo os resultados
beta0 <- result$par[1]
beta1 <- result$par[2]
optimal_value <- result$value

# Exibindo os resultados com três casas decimais
cat("Valor de beta0:", round(beta0, 3), "\n")
cat("Valor de beta1:", round(beta1, 3), "\n")
cat("Valor da função objetivo no ponto ótimo:", round(optimal_value, 3), "\n")

```






# 2 (correta)

Encontre os valores de $β_0$ e $β_1$ que otimizam a seguinte função\
(descobrir se é um problema de maximização ou minimização é parte da questão).\
Utilize o método BFGS usando as opções `default` da função `optim()` em R.

$$
L = 
\sum^n_{i=1} \;
(y_i−μ_i)^2
\text{,   onde } \;
μ_i = β_0 + β_1 x_i.
$$

Como valores para $y_i$ e $x_i$ considere os seguintes valores.\
Na notação $n$ é o número de observações.\
Neste exercício $n=10$.\
Sua resposta são três valores: valor de $β_0$ , valor de $β_1$ e valor da função objetivo no ponto ótimo.\
Use três casas decimais.\
Use como valores iniciais $β_0=0$ e $β_1=0$.\
$x_i = 4, 5, 4, 2, 2, 0, 1, 4, 1, 2$\
$y_i = 1.069, 1.597, 1.290, -0.747, -0.847, 0.197, -1.049, 1.303, -0.557, -0.958$

```{r 2}
# Dados fornecidos
xi <- c(4, 5, 4, 2, 2, 0, 1, 4, 1, 2)
yi <- c(1.069, 1.597, 1.290, -0.747, -0.847, 0.197, -1.049, 1.303, -0.557, -0.958)
n <- length(xi)

# Função objetivo
objective_function <- function(beta) {
  beta0 <- beta[1]
  beta1 <- beta[2]
  mu <- beta0 + beta1 * xi
  L <- sum((yi - mu)^2)
  return(L)
}

# Valores iniciais
initial_values <- c(0, 0)

# Otimização utilizando o método BFGS
result <- optim(par = initial_values, fn = objective_function, method = "BFGS")

# Extraindo os resultados
beta0 <- result$par[1]
beta1 <- result$par[2]
optimal_value <- result$value

# Exibindo os resultados com três casas decimais
cat("Valor de beta0:", round(beta0, 3), "\n")
cat("Valor de beta1:", round(beta1, 3), "\n")
cat("Valor da função objetivo no ponto ótimo:", round(optimal_value, 3), "\n")
```






# 3 (correta)

Obtenha a derivada numérica usando o método de diferença finita central com dois pontos da função

$$
f(x)= 7x^2 + 6x + 2
$$ e avalie no ponto $x=5$.\
A sua resposta é um número.\
Use três casas decimais se necessário.\
Use $h=0.001$

```{r 3}
# Definindo a função f(x)
f <- function(x) {
  return(7*(x^2) + 6*x + 2)
}

# Ponto onde queremos avaliar a derivada
x <- 5

# Tamanho do intervalo (passo)
h <- 0.001

# Calculando a derivada numérica usando o método de diferença finita central
df_numeric <- ( f(x + h) - f(x - h)) / (2 * h)

# Exibindo o resultado
cat("A derivada numérica de f(x) no ponto x = 5 é:", df_numeric, "\n")
```

# 4 (correta)

Resolva a seguinte integral usando algum método da classe dos métodos baseados em quadratura Gaussiana.\
A escolha do método adequado é parte da questão.\
Use $21$ pontos de integração.\
Use $\lambda$ igual a $7867$.\
Sua resposta é um número.\
Use três casas decimais.

$$
\int_0^{\infty} 
(\lambda 3^{-t}) \;
\exp(-0.12t) \;
dt
$$

```{r 4}
library(pracma)

# Função Gauss-Laguerre (gaussLaguerre do pkcg pracma)
gauss_laguerre <- function(integrando, n.pontos, ...){
  pontos <- gaussLaguerre(n.pontos)
  integral <- sum(pontos$w * integrando(pontos$x, ...) / exp(-pontos$x))
  return(integral)
}
# função a ser integrada
f <- function(t, lambda) {
  return((lambda * 3^(-t)) * exp(-0.12 * t))
}

n <- 21
lambda <- 7867

# Calculando a integral
integral <- gauss_laguerre(integrando = f, n.pontos = n, lambda = lambda)
integral
```

# 5 (correta)

Resolva a seguinte integral usando o método de Gauss-Legendre.\
Use $19$ pontos de integração e considere\
o limite inferior de integração $(a=0.1)$\
e o limite superior de integração $(b = 12.1)$.\
Na Equação considere os valores de $\lambda$ igual a $8$ e $k$ igual a $5$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{a}^b 
\frac{k}{\lambda} 
\left( \frac{y}{\lambda} \right)^{k-1} 
exp^{-(\frac{y}{\lambda})^k} 
dy
$$

```{r 5}
# Definir os parâmetros da integral
lambda <- 8
k <- 5
a <- 0.1
b <- 12.1

# Função a ser integrada
fy <- function(y) {
  return( (k / lambda) * (y / lambda)^(k - 1) * exp(-(y / lambda)^k))
}

# Função gauss_legendre fornecida
gauss_legendre <- function(integrando, n.pontos, a, b, ...) {
  pontos <- gaussLegendre(n.pontos, a = a, b = b)
  integral <- sum(pontos$w * integrando(pontos$x, ...))
  return(integral)
}

# Calcular a integral usando Gauss-Legendre com 19 pontos
n.pontos <- 19
result <- gauss_legendre(fy, n.pontos, a, b)
result

# Exibir o resultado com três casas decimais
cat("O valor da integral é:", round(result, 3), "\n")
```

# 6 (correta)

Resolva a seguinte integral usando o método de Gauss-Legendre.\
Use $15$ pontos de integração e considere\
o limite inferior de integração $(a= 0.1)$\
e o limite superior de integração $(b= 8.1)$.\
Na Equação considere os valores de $\alpha$ igual a $2$ e $\beta$ igual a $3$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{a}^b 
\frac
  { \beta^\alpha y^{\alpha-1} \exp^{(-\beta y)} }
  { \Gamma (\alpha) } 
dy
$$

Resposta:

A equação para o problema é:
$$
\int_{0.1}^{8.1} 
\frac
  { 3^2 y^{2-1} \exp^{(-3 y)} }
  { \Gamma (2) } 
dy
$$

```{r 6, options}
library(pracma) # para a funcao gaussLegrendre
# Nota a funcao gaussLegrendre opera dentro da funcao gauss_legrendre criada manualmente.
# ela fornece os pesos e pontos de integração.

# Definir os parâmetros da integral
alpha <- 2
beta <- 3
a <- 0.1
b <- 8.1

# Função a ser integrada
integrand <- function(y) {
  numerator <- beta^alpha * y^(alpha - 1) * exp(-beta * y)
  denominator <- gamma(alpha)
  return(numerator / denominator)
}

# Função gauss_legendre fornecida
gauss_legendre <- function(integrando, n.pontos, a, b, ...) {
  pontos <- gaussLegendre(n.pontos, a = a, b = b)
  integral <- sum(pontos$w * integrando(pontos$x, ...))
  return(integral)
}

# Calcular a integral usando Gauss-Legendre com 15 pontos
n.pontos <- 15
result <- gauss_legendre(integrand, n.pontos, a, b)

# Exibir o resultado com três casas decimais
cat("O valor da integral é:", round(result, 3), "\n")
```


# 7

Com relação as abordagens para diferenciação numérica assinale a única alternativa incorreta.\
Escolha uma opção:\
a. Se baseiam na ideia de aproximar o limite que define a derivada de forma aproximada computacionalmente.\
b. São métodos baseados em diferenças finitas.\
c. São métodos baseados em aproximar a função original por uma outra função de fácil derivação.\*\
d. O estado da arte em termos de derivadas numéricas é o método de diferenciação automática.\
e. São métodos baseados em truncar uma soma infinita.

# 8 (correta) (igual a 5)

Resolva a seguinte integral usando o método de Gauss-Legendre.\
Use $18$ pontos de integração e considere\
o limite inferior de integração $(a= 0.1)$ e\
o limite superior de integração $(b= 8.1)$.\
Na Equação considere os valores de $\lambda$ igual a $12$ e $k$ igual a $5$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{a}^b 
\frac{k}{\lambda} 
\left( \frac{y}{\lambda} \right)^{k-1} 
\exp^{-(\frac{y}{\lambda})^k} 
dy
$$

```{r 8}
# Definir os parâmetros da integral
lambda <- 12
k <- 5
a <- 0.1
b <- 8.1

# Função a ser integrada
fy <- function(y) {
  return( (k / lambda) * (y / lambda)^(k - 1) * exp(-(y / lambda)^k))
}

# Função gauss_legendre fornecida
gauss_legendre <- function(integrando, n.pontos, a, b, ...) {
  pontos <- gaussLegendre(n.pontos, a = a, b = b)
  integral <- sum(pontos$w * integrando(pontos$x, ...))
  return(integral)
}

# Calcular a integral usando Gauss-Legendre com 19 pontos
n.pontos <- 18
result <- gauss_legendre(fy, n.pontos, a, b)
result

# Exibir o resultado com três casas decimais
cat("O valor da integral é:", round(result, 3), "\n")

```

# 9 (correta)

Calcule as derivadas parciais numéricas de primeira e segunda ordem da seguinte função de duas variáveis:

$$
u = 
\exp^{(x^2)} 
+ \exp^{(y^2)}
$$

Use o método de Richardson com $h = 0.00001$.\
Avalie cada uma das derivadas no ponto $x=1$ e $y=2$.\
A resposta são seis valores numéricos na seguinte ordem:

$u_x; u_y; u_{xx}; u_{yy}; u_{xy} e u_{yx}$.

Use arredondamento com três casas decimais para a sua resposta.

```{r 9}
# Função a ser diferenciada
f <- function(x, y) {
  return(exp(x^2) + exp(y^2))
}

# Ponto de avaliação
x <- 1
y <- 2

# Passo
h <- 0.00001

# Derivadas parciais de primeira ordem (ux e uy) usando o método de Richardson
ux <- (f(x + h, y) - f(x, y)) / h
uy <- (f(x, y + h) - f(x, y)) / h

# Derivadas parciais de segunda ordem (uxx, uyy e uxy) usando o método de Richardson
uxx <- (f(x + 2*h, y) - 2*f(x + h, y) + f(x, y)) / (h^2)
uyy <- (f(x, y + 2*h) - 2*f(x, y + h) + f(x, y)) / (h^2)
uxy <- (f(x + h, y + h) - f(x + h, y) - f(x, y + h) + f(x, y)) / (h^2)

# Exibindo os resultados
cat("u_x:", round(ux, 3), "\n")
cat("u_y:", round(uy, 3), "\n")
cat("u_xx:", round(uxx, 3), "\n")
cat("u_yy:", round(uyy, 3), "\n")
cat("u_xy:", round(uxy, 3), "\n")
cat("u_yx:", round(uxy, 3), "\n")
```

# 10 (correta)

Determine a raiz cúbica de $300$ obtendo a solução numérica da equação

$$
f(x)=x^3−300=0
$$ usando o método da regula falsi.\
Use tolerância de $0.0001$.\
A escolha do intervalo adequado é parte da questão.\
Como critério para parada utilize o erro estimado, ou seja,\
$|x_{i+1}−x_{i}|< \epsilon$\
, onde $\epsilon$ é o erro tolerado.\
A sua resposta é o valor da raiz use três casas decimais se necessário.

```{r 10}
# Função que define a equação
f <- function(x) {
  return(x^3 - 300)
}

# Método da regula falsi
regula_falsi <- function(fx, a, b, tol = 1e-04, max_iter = 100) {
  fa <- fx(a); fb <- fx(b)
  if (fa * fb > 0) stop("Solução não está no intervalo")
  solucao <- c(); sol <- (a * fx(b) - b * fx(a)) / (fx(b) - fx(a))
  solucao[1] <- sol; limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for (i in 1:max_iter) {
    test <- fx(a) * fx(sol)
    if (test < 0) {
      b <- sol
    } else {
      a <- sol
    }
    solucao[i + 1] <- (a * fx(b) - b * fx(a)) / (fx(b) - fx(a))
    if (abs(solucao[i + 1] - solucao[i]) < tol) break
    sol <- solucao[i + 1]
    limites[i, ] <- c(a, b)
  }
  out <- list("Tentativas" = solucao, "Limites" = limites, "Raiz" = sol)
  return(out)
}

# Intervalo inicial
a <- 6
b <- 7

# Erro tolerado
epsilon <- 0.0001

# Solução utilizando o método da regula falsi
result <- regula_falsi(fx = f, a = a, b = b, tol = epsilon)

# Extraindo o valor da raiz
raiz <- result$Raiz

# Exibindo o valor da raiz com três casas decimais
cat("A raiz cúbica de 300 é:", round(raiz, 3), "\n")

```

# 11 (correta)

Resolva a seguinte integral usando algum método da classe dos métodos baseados em quadratura Gaussiana.\
A escolha do método adequado é parte da questão. Use $19$ pontos de integração.\
Na equação o valor de $\lambda$ é igual a $-0.033$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{-\infty}^{\infty} 
\lambda \; 
\exp(-(x-\lambda)^2) \;
dx
$$

```{r 11}
# Função gauss_laguerre adaptada para calcular a integral fornecida
gauss_laguerre <- function(integrando, n.pontos, lambda) {
  pontos <- gaussLaguerre(n.pontos)
  integral <- sum(pontos$w * integrando(pontos$x, lambda))
  return(integral)
}

# Função a ser integrada
integrando <- function(x, lambda) {
  return(lambda * exp(-x^2))
}

# Parâmetros fornecidos
lambda <- -0.033
n <- 19  # Número de pontos de integração

# Calculando a integral usando a função gauss_laguerre
integral <- gauss_laguerre(integrando, n, lambda)

# Exibindo o resultado
cat("O valor da integral é:", round(integral, 3), "\n")
```

# 12 (correta) (igual ao 6)

Resolva a seguinte integral usando o método de Gauss-Legendre.\
Use $22$ pontos de integração e considere\
o limite inferior de integração $(a=0.1)$\
e o limite superior de integração $(b= 11.1)$.\
Na Equação considere os valores de $\alpha$ igual a $2$ e $\beta$ igual a $3$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{a}^b 
\frac
  {\beta^\alpha y^{\alpha-1} \exp^{(-\beta y)}}
  {\Gamma(\alpha)} \;
dy
$$


Resposta:

A equação para o problema é:
$$
\int_{0.1}^{11.1} 
\frac
  { 3^2 y^{2-1} \exp^{(-3 y)} }
  { \Gamma (2) } 
dy
$$

```{r 12}
library(pracma) # para a funcao gaussLegrendre
# Nota a funcao gaussLegrendre opera dentro da funcao gauss_legrendre criada manualmente.
# ela fornece os pesos e pontos de integração.

# Definir os parâmetros da integral
alpha <- 2
beta <- 3
a <- 0.1
b <- 11.1

# Função a ser integrada
integrand <- function(y) {
  numerator <- beta^alpha * y^(alpha - 1) * exp(-beta * y)
  denominator <- gamma(alpha)
  return(numerator / denominator)
}

# Função gauss_legendre fornecida
gauss_legendre <- function(integrando, n.pontos, a, b, ...) {
  pontos <- gaussLegendre(n.pontos, a = a, b = b)
  integral <- sum(pontos$w * integrando(pontos$x, ...))
  return(integral)
}

# Calcular a integral usando Gauss-Legendre com 15 pontos
n.pontos <- 22
result <- gauss_legendre(integrand, n.pontos, a, b)

# Exibir o resultado com três casas decimais
cat("O valor da integral é:", round(result, 3), "\n")
```

# 13

Resolva a seguinte integral usando algum método da classe dos métodos baseados em quadratura Gaussiana.\
A escolha do método adequado é parte da questão.\
Use $17$ pontos de integração.\
Na equação o valor de $\lambda$ é igual a $9$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{0}^{\infty} 
\lambda \; 
\frac
  { \exp^{-\sqrt{x}} }
  { \sqrt{x} } 
dx 
$$

```{r 13}
# Função gauss_laguerre adaptada para calcular a integral fornecida
gauss_laguerre <- function(integrando, n.pontos, lambda) {
  pontos <- gaussLaguerre(n.pontos)
  integral <- sum(pontos$w * integrando(pontos$x, lambda))
  return(integral)
}

# Função a ser integrada
integrando <- function(x, lambda) {
  return(lambda * exp(-sqrt(x)) / sqrt(x))
}

# Parâmetros fornecidos
lambda <- 9
n <- 17  # Número de pontos de integração

# Calculando a integral usando a função gauss_laguerre
integral <- gauss_laguerre(integrando, n, lambda)

# Exibindo o resultado
cat("O valor da integral é:", round(integral, 3), "\n")

```

# 14

Resolva a seguinte integral usando algum método da classe dos métodos baseados em quadratura Gaussiana.
A escolha do método adequado é parte da questão.
Use $21$ pontos de integração.
Use $\lambda$ igual a $8098$.
Sua resposta é um número. Use três casas decimais.

$$
\int_0^{\infty} 
(\lambda \, 3^{-t}) 
\exp(-0.12t) \;
dt
$$

Resposta:

Para aplicar a quadratura de Gauss-Laguerre, é necessário que a integral esteja na forma:

$$ \int_0^\infty f(t) e^{-t} \, dt $$

No entanto, a integral fornecida no exercício não está exatamente nesse formato devido ao termo \(\exp(-0.12t)\). 
A integral original é:

$$ \int_0^{\infty} \lambda \, 3^{-t} \exp(-0.12t) \, dt $$

### Por que Precisamos Reescrever a Integral?

A quadratura de Gauss-Laguerre é especificamente projetada para integrais com o fator \(e^{-t}\). 
Para adaptar a integral fornecida ao formato requerido pela quadratura de Gauss-Laguerre, 
podemos fazer uma substituição que transforma o fator \(\exp(-0.12t)\) em \(e^{-u}\).

### Substituição

Usamos a substituição \( u = 0.12t \). 
Isso nos dá \( t = \frac{u}{0.12} \) e \( dt = \frac{du}{0.12} \). 
Substituindo esses valores na integral original, obtemos:

$$ \int_0^{\infty} \lambda \, 3^{-t} \exp(-0.12t) \, dt $$

Se torna:

$$ \int_0^{\infty} \lambda \, 3^{-\frac{u}{0.12}} \exp(-u) \frac{du}{0.12} $$

### Ajustando a Integral

Agora podemos ajustar a integral:

$$ 
\int_0^{\infty} \lambda \, 3^{-\frac{u}{0.12}} \exp(-u) \frac{du}{0.12} \\ = \frac{\lambda}{0.12} \int_0^{\infty} 3^{-\frac{u}{0.12}} \exp(-u) \, du 
$$

Esta forma é adequada para a quadratura de Gauss-Laguerre, onde 
$$
f(u) = \frac{\lambda}{0.12} 3^{-\frac{u}{0.12}} 
$$.

### Aplicação da Quadratura de Gauss-Laguerre

Com essa transformação, podemos aplicar a quadratura de Gauss-Laguerre para calcular a integral. A função \( f(u) \) é agora compatível com o formato necessário para usar os pontos e pesos da quadratura de Gauss-Laguerre.




```{r 14}
# Função Gauss-Laguerre adaptada para calcular a integral fornecida
gauss_laguerre <- function(integrando, n.pontos, lambda) {
  pontos <- gaussLaguerre(n.pontos)
  integral <- sum(pontos$w * integrando(pontos$x, lambda))
  return(integral)
}

# Função a ser integrada
integrando <- function(u, lambda) {
  return((lambda / 0.12) * 3^(-u / 0.12))
}

# Parâmetros fornecidos
lambda <- 8098
n <- 21  # Número de pontos de integração

# Calculando a integral usando a função gauss_laguerre
integral <- gauss_laguerre(integrando, n, lambda)
integral
# Exibindo o resultado
cat("O valor da integral é:", round(integral, 3), "\n")

```

# 15

Resolva a seguinte integral usando algum método da classe dos métodos baseados em simulação.\
A escolha do método adequado é parte da questão.\
Use $975$ pontos de integração.\
Na equação o valor de $k$ é igual a $2$.\
Como este método é baseado em simulação antes de usá-lo fixe a semente em 123 usando o comando set.seed(123).

$$
\int_{-\infty}^{\infty} 
\frac
  {1}
  {k + k^{-1}} 
\;
\exp(\frac{-x}{k}) \;
dx
$$

```{r 15}
# Fixando a semente para garantir reprodutibilidade
set.seed(123)

# Número de pontos de integração
n <- 975

# Valor de κ
k <- 2

# Função a ser integrada
integrando <- function(x, k) {
  return(1 / (k + 1/k) * exp(-x / k))
}

# Amostragem de Monte Carlo
amostras <- rexp(n, rate = k)

# Calculando a média das amostras multiplicadas pela função integrando
integral <- mean(integrando(amostras, k))

# Exibindo o resultado
cat("O valor da integral é:", round(integral, 3), "\n")

```

# 16

Com relação aos métodos de diferenciação numérica, assinale a única alternativa correta.\
Escolha uma opção:\
a. Podem ser divididos entre métodos de confinamento e abertos.\
b. São indicados para quando a função que se quer derivar é cara de se obter computacionalmente.\
c. Não são indicados no caso da função a ser derivada não seja totalmente conhecida.\
d. Alguns se baseiam na ideia de truncar uma soma infinita.\*\
e. Alguns se baseiam na ideia de aproximar a função original por uma outra função de fácil derivação.

# 17 (correta)

Sobre o Método Trapezoidal, assinale a alternativa correta.\
Escolha uma opção:\
a. O método usa uma função linear para aproximar o integrando e integra a função aproximada de forma usual.\*\
b. Neste método o integrando é aproximado usando um polinômio de segundo grau.\
c. A ideia básica é reescrever o integrando como um somatório.\
d. O método corresponde a usar o método Gauss-Hermite adaptativo com apenas um ponto de integração.\
e. A ideia é tratar a integral como uma quantidade desconhecida da qual podemos retirar amostras para então estimar o valor da integral como uma média simples.

# 18 (correta) (igual a 6 e 12)

Resolva a seguinte integral usando o método de Gauss-Legendre.\
Use $20$ pontos de integração e considere\
o limite inferior de integração $(a=0.1)$ e\
o limite superior de integração $(b= 13.1)$.\
Na Equação considere os valores de $\alpha$ igual a $2$ e $\beta$ igual a $2$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{a}^b 
\frac
  {\beta^\alpha y^{\alpha-1} exp^{-\beta y}}
  {\Gamma(\alpha)}
dy
$$


Resposta:

A equação para o problema é:
$$
\int_{0.1}^{13.1} 
\frac
  { 2^2 y^{2-1} \exp^{(-2 y)} }
  { \Gamma (2) } 
dy
$$


```{r 18}
library(pracma) # para a funcao gaussLegrendre
# Nota a funcao gaussLegrendre opera dentro da funcao gauss_legrendre criada manualmente.
# ela fornece os pesos e pontos de integração.

# Definir os parâmetros da integral
alpha <- 2
beta <- 2
a <- 0.1
b <- 13.1

# Função a ser integrada
integrand <- function(y) {
  numerator <- beta^alpha * y^(alpha - 1) * exp(-beta * y)
  denominator <- gamma(alpha)
  return(numerator / denominator)
}

# Função gauss_legendre fornecida
gauss_legendre <- function(integrando, n.pontos, a, b, ...) {
  pontos <- gaussLegendre(n.pontos, a = a, b = b)
  integral <- sum(pontos$w * integrando(pontos$x, ...))
  return(integral)
}

# Calcular a integral usando Gauss-Legendre com 15 pontos
n.pontos <- 22
result <- gauss_legendre(integrand, n.pontos, a, b)

# Exibir o resultado com três casas decimais
cat("O valor da integral é:", round(result, 3), "\n")
```


# 19

Determine a raiz negativa mais próxima da origem do polinômio

$$
f(x)= x^3 + 3.8x^2 − 8.6x − 24.4
$$

usando o método da `regula falsi`.\
A escolha do intervalo de busca é parte da questão.\
Como critério para parada utilize o erro estimado, ou seja, $|xi+1−xi| < \epsilon$\
, onde $\epsilon$ é o erro tolerado.\
Use tolerância de $0.0001$.\
A escolha do intervalo adequado é parte da questão.\
A sua resposta é o valor da raiz use três casas decimais se necessário.

```{r 19}
# Definir a função do polinômio
f <- function(x) {
  return(x^3 + 3.8 * x^2 - 8.6 * x - 24.4)
}

# Algoritmo da regula falsi
regula_falsi <- function(fx, a, b, tol = 1e-04, max_iter = 100) {
  fa <- fx(a)
  fb <- fx(b)
  if (fa * fb > 0) stop("Solução não está no intervalo")
  solucao <- c()
  sol <- (a * fb - b * fa) / (fb - fa)
  solucao[1] <- sol
  limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for (i in 1:max_iter) {
    test <- fx(a) * fx(sol)
    if (test < 0) {
      b <- sol
    } else if (test > 0) {
      a <- sol
    } else {
      break
    }
    sol <- (a * fx(b) - b * fx(a)) / (fx(b) - fx(a))
    solucao[i + 1] <- sol
    limites[i, ] <- c(a, b)
    if (abs(solucao[i + 1] - solucao[i]) < tol) break
  }
  out <- list("Tentativas" = solucao, "Limites" = limites, "Raiz" = sol)
  return(out)
}

# Escolha do intervalo inicial
a <- -5
b <- 5

# Tolerância
tol <- 0.0001

# Resolver a equação usando o método da regula falsi
resultado <- regula_falsi(f, a, b, tol)

# Extrair a solução final
raiz <- resultado$Raiz

# Exibir o valor da raiz com três casas decimais
cat("O valor da raiz é:", round(raiz, 3), "\n")



```

# 20 (igual a 15)

Resolva a seguinte integral usando algum método da classe dos métodos baseados em simulação.\
A escolha do método adequado é parte da questão.\
Use $985$ pontos de integração.\
Na equação o valor de $k$ é igual a $0.5$.\
Como este método é baseado em simulação antes de usá-lo fixe a semente em $123$ usando o comando `set.seed(123)`.

$$
\int_{-\infty}^{\infty} 
\frac
  {1}
  {k + k^{-1}} 
\;
\exp(\frac{-x}{k}) \;
dx
$$

```{r 20}
# Definir a função do polinômio
f <- function(x) {
  return(x^3 - 2.2 * x^2 - 2.15 * x + 5.1)
}

# Algoritmo da bisseção
bissecao <- function(fx, a, b, tol = 1e-04, max_iter = 100) {
  fa <- fx(a)
  fb <- fx(b)
  if(fa * fb > 0) stop("Solução não está no intervalo")
  solucao <- c()
  sol <- (a + b) / 2
  solucao[1] <- sol
  limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for(i in 1:max_iter) {
    test <- fx(a) * fx(sol)
    if(test < 0) {
      solucao[i + 1] <- (a + sol) / 2
      b <- sol 
    } else if(test > 0) {
      solucao[i + 1] <- (b + sol) / 2
      a <- sol 
    } else {
      solucao[i + 1] <- sol
      break
    }
    if(abs((b - a) / 2) < tol) break
    sol <- solucao[i + 1]
    limites[i, ] <- c(a, b)
  }
  out <- list("Tentativas" = solucao, "Limites" = limites, "Raiz" = solucao[i + 1])
  return(out)
}

# Escolha do intervalo inicial
a <- 0
b <- -2

# Tolerância
tol <- 0.0001

# Resolver a equação usando o método da bisseção
resultado <- bissecao(f, a, b, tol)

# Extrair a solução final
raiz <- resultado$Raiz
raiz
# Exibir o valor da raiz com três casas decimais
cat("O valor da raiz é:", round(raiz, 3), "\n")

```

# 21 (igual a 11)

Resolva a seguinte integral usando algum método da classe dos métodos baseados em quadratura Gaussiana.\
A escolha do método adequado é parte da questão.\
Use 21 pontos de integração.\
Na equação o valor de $\lambda$ é igual a $0.091$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{-\infty}^{\infty} 
\lambda \; 
\exp(-(x-\lambda)^2) \;
dx
$$

```{r 21}
# Função gauss_laguerre adaptada para calcular a integral fornecida
gauss_laguerre <- function(integrando, n.pontos, lambda) {
  pontos <- gaussLaguerre(n.pontos)
  integral <- sum(pontos$w * integrando(pontos$x, lambda))
  return(integral)
}

# Função a ser integrada
integrando <- function(x, lambda) {
  return(lambda * exp(-x^2))
}

# Parâmetros fornecidos
lambda <- -0.091
n <- 21  # Número de pontos de integração

# Calculando a integral usando a função gauss_laguerre
integral <- gauss_laguerre(integrando, n, lambda)

# Exibindo o resultado
cat("O valor da integral é:", round(integral, 3), "\n")
```

# 22 (igual a 2)

Encontre os valores de $β0$ e $β1$ que otimizam a seguinte função\
(descobrir se é um problema de maximização ou minimização é parte da questão).\
Utilize o método Simulating Annealing (SANN) usando as opções `default` da função `optim()` em R.

$$
L = - \frac{1}{n} ; \sum^n_{i=1} \; (y_i \; \ln(\mu_i) + (1 - y_i) \; \ln(1-u_i) \;)

\text{,   onde } \; μ_i = \frac {\exp(β_0 + β_1 x_i)} {1 + \exp (β_0 + β_1 x_i)}

$$

Como valores para $y_i$ e $x_i$ considere os seguintes valores.\
Na notação $n$ é o número de observações. Neste exercício $n=10$.\
Sua resposta são três valores: valor de $β_0$, valor de $β_1$ e valor da função objetivo no ponto ótimo.\
Use três casas decimais. Use como valores iniciais $β_0=0$ e $β_1=0$.

$xi = 3, 0, 0, 4, 4, 4, 2, 1, 4, 4$\
$yi = 1, 0, 0, 1, 1, 1, 1, 1, 1, 1$

```{r 22}
# Dados fornecidos
xi <- c(3, 0, 0, 4, 4, 4, 2, 1, 4, 4)
yi <- c(1, 0, 0, 1, 1, 1, 1, 1, 1, 1)
n <- length(xi)

# Função objetivo
objective_function <- function(beta) {
  beta0 <- beta[1]
  beta1 <- beta[2]
  mu <- beta0 + beta1 * xi
  L <- sum((yi - mu)^2)
  return(L)
}

# Valores iniciais
initial_values <- c(0, 0)

# Otimização utilizando o método BFGS
result <- optim(par = initial_values, fn = objective_function, method = "BFGS")

# Extraindo os resultados
beta0 <- result$par[1]
beta1 <- result$par[2]
optimal_value <- result$value

# Exibindo os resultados com três casas decimais
cat("Valor de beta0:", round(beta0, 3), "\n")
cat("Valor de beta1:", round(beta1, 3), "\n")
cat("Valor da função objetivo no ponto ótimo:", round(optimal_value, 3), "\n")

```

# 23 (igual a 14)

Resolva a seguinte integral usando algum método da classe dos métodos baseados em quadratura Gaussiana.\
A escolha do método adequado é parte da questão.\
Use $20$ pontos de integração.\
Use $\lambda$ igual a $8002$.\
Sua resposta é um número. Use três casas decimais.

$$
\int_0^{\infty} 
(\lambda \, 3^{-t}) 
\exp(-0.12t) \;
dt
$$

```{r 23}
# Função Gauss-Laguerre adaptada para calcular a integral fornecida
gauss_laguerre <- function(integrando, n.pontos, lambda) {
  pontos <- gaussLaguerre(n.pontos)
  integral <- sum(pontos$w * integrando(pontos$x, lambda))
  return(integral)
}

# Função a ser integrada
integrando <- function(u, lambda) {
  return((lambda / 0.12) * 3^(-u / 0.12))
}

# Parâmetros fornecidos
lambda <- 8002
n <- 20  # Número de pontos de integração

# Calculando a integral usando a função gauss_laguerre
integral <- gauss_laguerre(integrando, n, lambda)
integral
# Exibindo o resultado
cat("O valor da integral é:", round(integral, 3), "\n")
```

# 24

Qual é a principal ideia por trás dos métodos baseados em gradiente?\
Escolha uma opção:\
a. Usar o gradiente para indicar a direção do máximo de uma função.\
b. Propor soluções de forma aleatória e a partir destas escolher as melhores para gerar novas soluções e assim sucessivamente.\
c. Usar apenas o gradiente para decidir o tamanho do passo na direção do máximo de uma função.\*\
d. Propor soluções de forma aleatória até que uma seja boa o bastante.\
e. Usar o hessiano para decidir a direção e o gradiente para definir o tamanho do passo.

# 25 (correta)

O método do Gradiente descendente em geral é usado para que tarefa?\
Escolha uma opção:\
a. Encontrar derivadas numericamente.\
b. Encontrar o mínimo ou máximo de uma função.\*\
c. Encontrar integrais numericamente.\
d. Decompor matrizes.\
e. Ajustar modelos de regressão penalizada.

# 26 (correta)

Resolva o seguinte sistema de equações não lineares usando o método de Newton.

$$
log(x^2 + 2y^2 + 1) − 0.5 = 0  \\
y − x^2 + 0.2 = 0
$$

A escolha de valor inicial é parte da questão.\
Como critério para parada utilize o erro estimado, ou seja, $|x_i+1−x_i| < \epsilon$, onde $\epsilon$ é o erro tolerado.\
Use tolerância de $0.0001$.\
A sua resposta são as duas raízes $\hat{x}$ e $\hat{y}$.\
Use três casas decimais se necessário.

Resposta:

Para o sistema de equações dado:
$$
\log(x^2 + 2y^2 + 1) - 0.5 = 0 \\
y - x^2 + 0.2 = 0
$$

Precisamos calcular a matriz Jacobiana, que contém as derivadas parciais de cada equação em relação a cada variável (\(x\) e \(y\)).

### Derivadas Parciais

**Primeira Equação:**
$$
\log(x^2 + 2y^2 + 1) - 0.5 = 0
$$

Derivada parcial em relação a \(x\):
$$
\frac{\partial}{\partial x} \left( \log(x^2 + 2y^2 + 1) \right) = \frac{2x}{x^2 + 2y^2 + 1}
$$

Derivada parcial em relação a \(y\):
$$
\frac{\partial}{\partial y} \left( \log(x^2 + 2y^2 + 1) \right) = \frac{4y}{x^2 + 2y^2 + 1}
$$

**Segunda Equação:**
$$
y - x^2 + 0.2 = 0
$$

Derivada parcial em relação a \(x\):
$$
\frac{\partial}{\partial x} \left( y - x^2 + 0.2 \right) = -2x
$$

Derivada parcial em relação a \(y\):
$$
\frac{\partial}{\partial y} \left( y - x^2 + 0.2 \right) = 1
$$

### Montagem da Matriz Jacobiana

A matriz Jacobiana \(J\) para o sistema de duas equações não lineares com duas variáveis (\(x\) e \(y\)) é uma matriz \(2 \times 2\) onde cada elemento \(J_{ij}\) é a derivada parcial da i-ésima equação em relação à j-ésima variável.

A Jacobiana é dada por:
$$
J = \begin{bmatrix}
\frac{\partial}{\partial x} \left( \log(x^2 + 2y^2 + 1) - 0.5 \right) & \frac{\partial}{\partial y} \left( \log(x^2 + 2y^2 + 1) - 0.5 \right) \\
\frac{\partial}{\partial x} \left( y - x^2 + 0.2 \right) & \frac{\partial}{\partial y} \left( y - x^2 + 0.2 \right)
\end{bmatrix}
= \begin{bmatrix}
\frac{2x}{x^2 + 2y^2 + 1} & \frac{4y}{x^2 + 2y^2 + 1} \\
-2x & 1
\end{bmatrix}
$$

### Implementação em R

O código R para calcular a Jacobiana é:


```{r 26}
# Definir as funções que representam o sistema de equações
fx <- function(x) {
  c(
    log(x[1]^2 + 2 * x[2]^2 + 1) - 0.5, 
    x[2] - x[1]^2 + 0.2
  )
}

# Definir a Jacobiana do sistema
jacobian <- function(x) {
  jac <- matrix(NA, 2, 2)
  jac[1, 1] <- 2 * x[1] / (x[1]^2 + 2 * x[2]^2 + 1)
  jac[1, 2] <- 4 * x[2] / (x[1]^2 + 2 * x[2]^2 + 1)
  jac[2, 1] <- -2 * x[1]
  jac[2, 2] <- 1
  return(jac)
}

# Função de Newton para sistemas de equações não lineares
newton_sa <- function(fx, jacobian, x1, tol = 1e-04, max_iter = 100) {
  solucao <- matrix(NA, ncol = length(x1), nrow = max_iter + 1)
  solucao[1, ] <- x1
  for(i in 1:max_iter) {
    J <- jacobian(solucao[i, ])
    grad <- fx(solucao[i, ])
    delta <- solve(J, grad)
    solucao[i + 1, ] <- solucao[i, ] - delta
    if(sum(abs(delta)) < tol) {
      solucao <- solucao[1:(i + 1), ]
      break
    }
  }
  return(solucao)
}

# Valor inicial
x1 <- c(0.5, 0.5)

# Tolerância
tol <- 1e-04

# Resolver o sistema usando o método de Newton
solucao <- newton_sa(fx = fx, jacobian = jacobian, x1 = x1, tol = tol)
solucao


# Extrair a solução final
raiz <- tail(solucao, 1)
raiz

```






# 27 (correta) (igual a 5 e 8)

Resolva a seguinte integral usando o método de Gauss-Legendre.\
Use $27$ pontos de integração e considere\
o limite inferior de integração $(a= 1.1)$ e\
o limite superior de integração $(b= 8.1)$.\
Na Equação considere os valores de $\lambda$ igual a $12$ e $k$ igual a 5.\
Sua resposta é um número. Use três casas decimais.

$$
\int_{a}^b \frac{k}{\lambda} \left( \frac{y}{\lambda} \right)^{k-1} exp^{-(\frac{y}{\lambda})^k}dy 
$$

```{r 27}
# Definir os parâmetros da integral
lambda <- 12
k <- 5
a <- 1.1
b <- 8.1

# Função a ser integrada
fy <- function(y) {
  return( (k / lambda) * (y / lambda)^(k - 1) * exp(-(y / lambda)^k))
}

# Função gauss_legendre fornecida
gauss_legendre <- function(integrando, n.pontos, a, b, ...) {
  pontos <- gaussLegendre(n.pontos, a = a, b = b)
  integral <- sum(pontos$w * integrando(pontos$x, ...))
  return(integral)
}

# Calcular a integral usando Gauss-Legendre com 19 pontos
n.pontos <- 27
result <- gauss_legendre(fy, n.pontos, a, b)
result

# Exibir o resultado com três casas decimais
cat("O valor da integral é:", round(result, 3), "\n")
```

# 28

Determine a raiz a direita do ponto crítico da equação:

$$
f (μ, y_i) = 
\sum_{i=1}^n \;
2 
\left\{ 
  y_i 
  \log \left( \frac{\frac{y_i}{10}}{\mu} \right) 
  +  
  (10 - y_i) 
  \log \left( \frac{1 - \frac{y_i}{10}}{1 - \mu} \right) 
\right\}
-3.84
$$

usando o método de Newton.\
A escolha de valor inicial é parte da questão.\
Como critério para parada utilize o erro estimado, ou seja, $|xi+1−xi| < \epsilon$\
, onde $\epsilon$ é o erro tolerado.\
Use tolerância de $0.0001$.\
A sua resposta é o valor da raiz use três casas decimais se necessário.

$y = 4, 6, 5, 7, 7, 2, 5, 7, 5, 5$


Resposta:

Definição da Função \( f(\mu) \):

A função \( f(\mu) \) é definida como:
$$
f(\mu) = \sum_{i=1}^n \; 2 \left\{ y_i \log \left( \frac{\frac{y_i}{10}}{\mu} \right) + (10 - y_i) \log \left( \frac{1 - \frac{y_i}{10}}{1 - \mu} \right) \right\} - 3.84
$$

Derivada da Função \( f(\mu) \):

A derivada da função \( f(\mu) \) em relação a \(\mu\) é calculada como:
$$
f'(\mu) = \sum_{i=1}^n \; 2 \left( -\frac{y_i}{\mu} + \frac{10 - y_i}{1 - \mu} \right)
$$

Implementação do Método de Newton:

A função `newton_method` é implementada para iterativamente encontrar a raiz da função \( f(\mu) \) usando a derivada \( f'(\mu) \).


A implementaçao computacional é:

```{r 28}
# Definindo os valores de y_i
y <- c(4, 6, 5, 7, 7, 2, 5, 7, 5, 5)
n <- length(y)


# Definindo a função f(mu)
ftheta <- function(mu) {
  sum_yi <- sum(sapply(y, function(yi) {
    2 * (yi * log((yi / 10) / mu) + (10 - yi) * log((1 - (yi / 10)) / (1 - mu)))
  }))
  return(sum_yi - 3.84)
}

# Definindo a derivada f'(mu)
fprime <- function(mu) {
  sum_yi_prime <- sum(sapply(y, function(yi) {
    2 * (-yi / mu + (10 - yi) / (1 - mu))
  }))
  return(sum_yi_prime)
}


# Algoritmo de Newton
newton_method <- function(fx, f_prime, x1, tol = 1e-04, max_iter = 25) {
  solucao <- c()
  solucao[1] <- x1
  for (i in 1:max_iter) {
    solucao[i + 1] <- solucao[i] - fx(solucao[i]) / f_prime(solucao[i])
    if (abs(solucao[i + 1] - solucao[i]) < tol) break
  }
  return(solucao)
}


# Valor inicial para a raiz à direita do ponto crítico
mu_initial <- 0.1

# Tolerância
tol <- 1e-04

# Resolver a equação usando o método de Newton
raiz <- newton_method(fx = ftheta, f_prime = fprime, x1 = mu_initial, tol = tol)
raiz

# Extrair a solução final
raiz_final <- tail(raiz, 1)

# Exibir o valor da raiz com três casas decimais
cat("O valor da raiz é:", round(raiz_final, 3), "\n")

```

# 29 (correta)

Determine a raiz positiva do polinômio

$$
f(x) = x^2 − 3x + exp^x − 2
$$

usando o método da bisseção.\
A escolha do intervalo de busca é parte da questão.\
Como critério para parada utilize o erro estimado, ou seja, $|xi+1−xi| < \epsilon$\
, onde $\epsilon$ é o erro tolerado.\
Use tolerância de $0.0001$.\
A escolha do intervalo adequado é parte da questão.\
A sua resposta é o valor da raiz use três casas decimais se necessário.


Resposta:

Para resolver a raiz positiva do polinômio \( f(x) = x^2 - 3x + \exp(x) - 2 \) usando o método da bisseção, siga os seguintes passos:

1. Defina a função do polinômio \( f(x) \).
2. Utilize o algoritmo da bisseção para encontrar a raiz da função \( f(x) \).
3. Escolha o intervalo inicial de busca.
4. Defina a tolerância \(\epsilon\) e o critério de parada.
5. Execute o método da bisseção até que o critério de parada seja satisfeito.
6. Exiba o valor da raiz com três casas decimais.



```{r 29}
# Definir a função do polinômio
f <- function(x) {
  return(x^2 - 3*x + exp(x) - 2)
}

# Algoritmo da bisseção
bissecao <- function(fx, a, b, tol = 1e-04, max_iter = 100) {
  fa <- fx(a)
  fb <- fx(b)
  if(fa * fb > 0) stop("Solução não está no intervalo")
  solucao <- c()
  sol <- (a + b) / 2
  solucao[1] <- sol
  limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for(i in 1:max_iter) {
    test <- fx(a) * fx(sol)
    if(test < 0) {
      solucao[i + 1] <- (a + sol) / 2
      b <- sol 
    } else if(test > 0) {
      solucao[i + 1] <- (b + sol) / 2
      a <- sol 
    } else {
      solucao[i + 1] <- sol
      break
    }
    if(abs((b - a) / 2) < tol) break
    sol <- solucao[i + 1]
    limites[i, ] <- c(a, b)
  }
  out <- list("Tentativas" = solucao, "Limites" = limites, "Raiz" = solucao[i + 1])
  return(out)
}

# Escolha do intervalo inicial
a <- 0
b <- 2

# Tolerância
tol <- 0.0001

# Resolver a equação usando o método da bisseção
resultado <- bissecao(f, a, b, tol)

# Extrair a solução final
raiz <- resultado$Raiz

# Exibir o valor da raiz com três casas decimais
cat("O valor da raiz é:", round(raiz, 3), "\n")


```

# 30

Determine a raiz a esquerda do ponto crítico da equação:

$$
f (μ, y_i) = 
\sum_{i=1}^n \;
2y_i \;
\log 
\left( \frac{y_i}{\mu} - y_i + \mu \right) 
-3.84
$$

usando o método do gradiente descendente.\
A escolha de valor inicial e do parâmetro de tuning é parte da questão.\
Como critério para parada utilize o erro estimado, ou seja, $|xi+1−xi| < \epsilon$\
, onde $\epsilon$ é o erro tolerado.\
Use tolerância de $0.0001$.\
A sua resposta é o valor da raiz use três casas decimais se necessário.\
Na equação os valores para $y_i$ são dados abaixo.\
Dica: A função subjacente (que deu origem a equação a ser resolvida) está sendo maximizada.

$y = 8, 9, 14, 10, 10, 15, 11, 5, 4, 13$

```{r 30}
# Definir os valores de y_i
y <- c(8, 9, 14, 10, 10, 15, 11, 5, 4, 13)
n <- length(y)

# Definir a função f(mu)
ftheta <- function(mu) {
  if (mu <= 0) return(-Inf)  # Para evitar divisão por zero ou log de número negativo
  sum_yi <- sum(sapply(y, function(yi) {
    val <- (yi / mu) - yi + mu
    if (val <= 0) return(-Inf)  # Garantir que o argumento do log é positivo
    2 * yi * log(val)
  }))
  return(sum_yi - 3.84)
}

# Definir a derivada da função f(mu)
fprime <- function(mu) {
  if (mu <= 0) return(-Inf)  # Para evitar divisão por zero
  sum_yi_prime <- sum(sapply(y, function(yi) {
    2 * yi * (-yi / (mu^2) + 1)
  }))
  return(sum_yi_prime)
}

## Algoritmo de gradiente descendente usando a função fornecida
grad_des_ma <- function(fx, x1, alpha, max_iter = 100, tol = 1e-04) {
  sol <- c()
  sol[1] <- x1
  for(i in 1:max_iter) {
    sol[i+1] <- sol[i] - alpha * fx(sol[i])
    if(abs(fx(sol[i+1])) < tol) break
  }
  return(sol)
}

# Valor inicial e parâmetro de tuning (alpha)
mu_initial <- 0.1
alpha <- 0.0001  # Ajustar a taxa de aprendizagem para um valor adequado

# Tolerância
tol <- 0.0001

# Resolver a equação usando o método do gradiente descendente para maximização
solucao <- grad_des_ma(fx = fprime, x1 = mu_initial, alpha = alpha, tol = tol)

# Extrair a solução final
raiz <- tail(solucao, 1)

# Exibir o valor da raiz com três casas decimais
cat("O valor da raiz é:", round(raiz, 3), "\n")

```

# 31

Determine a raiz a esquerda do ponto crítico da equação:

$$
f (μ, y_i) = 
\sum_{i=1}^n 2 
\left\{ 
  y_i 
  \log \left( \frac{\frac{y_i}{m_i}}{\mu} \right) 
  + (m - y_i) 
  \log \left( \frac{1 - \frac{y_i}{\mu}}{1 - \mu} \right) 
\right\}
-3.84
$$ 

usando o método do gradiente descendente.
A escolha de valor inicial e do parâmetro de tuning é parte da questão.
Como critério para parada utilize o erro estimado, ou seja, $|xi+1−xi|< \epsilon$
, onde $epsilon$ é o erro tolerado.
Use tolerância de $0.0001$.
A sua resposta é o valor da raiz use três casas decimais se necessário.
Na equação os valores para y_i são dados abaixo.
Dica: A função subjacente (que deu origem a equação a ser resolvida) está sendo maximizada.

$y = 4, 6, 5, 7, 7, 2, 5, 7, 5, 5$

```{r 31}
# Definir os valores de y_i
y <- c(4, 6, 5, 7, 7, 2, 5, 7, 5, 5)
n <- length(y)
m <- 10  # Valor fixo para m

# Definir a função f(mu)
ftheta <- function(mu) {
  if (mu <= 0 || mu >= 1) return(Inf)  # Para evitar valores inválidos para log
  sum_yi <- sum(sapply(y, function(yi) {
    term1 <- yi * log((yi / m) / mu)
    term2 <- (m - yi) * log((1 - (yi / m)) / (1 - mu))
    2 * (term1 + term2)
  }))
  return(sum_yi - 3.84)
}

# Definir a derivada da função f(mu)
fprime <- function(mu) {
  if (mu <= 0 || mu >= 1) return(Inf)  # Para evitar valores inválidos para log
  sum_yi_prime <- sum(sapply(y, function(yi) {
    term1 <- -yi / (mu * m)
    term2 <- (m - yi) / (m * (1 - mu))
    2 * (term1 + term2)
  }))
  return(sum_yi_prime)
}

## Algoritmo de gradiente descendente usando a função fornecida
grad_des_ma <- function(fx, x1, alpha, max_iter = 100, tol = 1e-04) {
  sol <- c()
  sol[1] <- x1
  for(i in 1:max_iter) {
    sol[i+1] <- sol[i] - alpha * fx(sol[i])
    if(abs(fx(sol[i+1])) < tol) break
  }
  return(sol)
}

# Valor inicial e parâmetro de tuning (alpha)
mu_initial <- 0.5
alpha <- 0.0001  # Ajustar a taxa de aprendizagem para um valor adequado

# Tolerância
tol <- 0.0001

# Resolver a equação usando o método do gradiente descendente para maximização
solucao <- grad_des_ma(fx = fprime, x1 = mu_initial, alpha = alpha, tol = tol)

# Extrair a solução final
raiz <- tail(solucao, 1)

# Exibir o valor da raiz com três casas decimais
cat("O valor da raiz é:", round(raiz, 3), "\n")
```

# 32 (igual a 29)

Determine a raiz positiva do polinômio:
$$
f(x) = x^3 − 2.2x^2 − 2.15x + 5.1
$$ 

usando o método da bisseção. 
A escolha do intervalo de busca é parte da questão. Como critério para parada 
utilize o erro estimado, ou seja, $|xi+1−xi|< \epsilon$
, onde $\epsilon$ é o erro tolerado.
Use tolerância de $0.0001$.
A escolha do intervalo adequado é parte da questão.\
A sua resposta é o valor da raiz use três casas decimais se necessário.

```{r 29, options}
# Definir a função do polinômio
f <- function(x) {
  return(x^3 - 2.2 * x^2 + 2.15*x + 5.1)
}

# Algoritmo da bisseção
bissecao <- function(fx, a, b, tol = 1e-04, max_iter = 100) {
  fa <- fx(a)
  fb <- fx(b)
  if(fa * fb > 0) stop("Solução não está no intervalo")
  solucao <- c()
  sol <- (a + b) / 2
  solucao[1] <- sol
  limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for(i in 1:max_iter) {
    test <- fx(a) * fx(sol)
    if(test < 0) {
      solucao[i + 1] <- (a + sol) / 2
      b <- sol 
    } else if(test > 0) {
      solucao[i + 1] <- (b + sol) / 2
      a <- sol 
    } else {
      solucao[i + 1] <- sol
      break
    }
    if(abs((b - a) / 2) < tol) break
    sol <- solucao[i + 1]
    limites[i, ] <- c(a, b)
  }
  out <- list("Tentativas" = solucao, "Limites" = limites, "Raiz" = solucao[i + 1])
  return(out)
}

# Escolha do intervalo inicial
a <- -1
b <- 1

# Tolerância
tol <- 0.0001

# Resolver a equação usando o método da bisseção
resultado <- bissecao(f, a, b, tol)

# Extrair a solução final
raiz <- resultado$Raiz
raiz
# Exibir o valor da raiz com três casas decimais
cat("O valor da raiz é:", round(raiz, 3), "\n")


```
. FIM
